{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Define Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "input_path = './chest_Xray/'\n",
    "img_dims = 150\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def process_data(img_dims, batch_size):\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "\n",
    "    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n",
    "        for img in (os.listdir(input_path + 'test' + cond)):\n",
    "            img = plt.imread(input_path+'test'+cond+img)\n",
    "            img = cv2.resize(img, (img_dims, img_dims))\n",
    "            img = np.dstack([img, img, img])\n",
    "            img = img.astype('float32') / 255\n",
    "            if cond == '/NORMAL/':\n",
    "                label = 0\n",
    "            elif cond == '/PNEUMONIA/':\n",
    "                label = 1\n",
    "            test_data.append(img)\n",
    "            test_labels.append(label)\n",
    "        \n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return test_data, test_labels"
   ]
  },
  {
   "source": [
    "# Import Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_normal = len(os.listdir(input_path + 'test' + '/NORMAL'))\n",
    "n_infect = len(os.listdir(input_path + 'test' + '/PNEUMONIA'))\n",
    "print('Set: {}, normal images: {}, pneumonia images: {}'.format(\n",
    "    'test', n_normal, n_infect))\n",
    "\n",
    "test_data, test_labels = process_data(\n",
    "    img_dims, batch_size)"
   ]
  },
  {
   "source": [
    "# Import pre-trained Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "modelList = []\n",
    "for fold in os.listdir('./saved_models_v2/'):\n",
    "    m = load_model('./saved_models_v2/' + fold)\n",
    "    modelList.append([m, fold])\n",
    "    print(\"Imported: {}/{}\".format(len(modelList),\n",
    "          len(os.listdir('./saved_models_v2/'))))\n",
    "    clear_output(wait=True)\n",
    "print(\"Import OK\")"
   ]
  },
  {
   "source": [
    "# Evaluate Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "i = 0\n",
    "max_index_acc = 0\n",
    "max_index_f = 0\n",
    "max_name_acc = \"\"\n",
    "max_name_f = \"\"\n",
    "max_acc = 0\n",
    "max_f = 0\n",
    "for model in modelList:\n",
    "    print(\"{}/{} - {}\".format(i + 1, len(modelList), model[1]), end=\" - \")\n",
    "    loss, acc = model[0].evaluate(\n",
    "        test_data, test_labels, verbose=2)\n",
    "    # preds = modelList[max_index_acc][0].predict(test_data)\n",
    "\n",
    "    # cm = confusion_matrix(test_labels, np.round(preds))\n",
    "    # tn, fp, fn, tp = cm.ravel()\n",
    "    # precision = tp/(tp+fp)*100\n",
    "    # recall = tp/(tp+fn)*100\n",
    "    # f = 2 * precision * recall/(precision + recall)\n",
    "    if (acc > max_acc):\n",
    "        max_acc = acc\n",
    "        max_name_acc = model[1]\n",
    "        max_index_acc = i\n",
    "    # if (f > max_f):\n",
    "    #     max_f = f\n",
    "    #     max_name_f = model[1]\n",
    "    #     max_index_f = i\n",
    "    i += 1\n",
    "\n",
    "    # print(model[1] + ' - Accuracy: {:5.2f}%'.format(100 * acc))\n",
    "print(\"\\nBest acc: {} at index: {}\\n\".format(max_name_acc, max_index_acc))\n",
    "# print(\"Best F1: {} at index: {}\".format(max_name_f, max_index_f))"
   ]
  },
  {
   "source": [
    "# Display most accurate model info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "preds = modelList[max_index_acc][0].predict(test_data)\n",
    "\n",
    "acc = accuracy_score(test_labels, np.round(preds))*100\n",
    "cm = confusion_matrix(test_labels, np.round(preds))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"--- DATA FOR MAX ACC AT {} ---\\n\".format(modelList[max_index_acc][1]))\n",
    "\n",
    "print('TEST METRICS ----------------------')\n",
    "precision = tp/(tp+fp)*100\n",
    "recall = tp/(tp+fn)*100\n",
    "f = 2 * precision * recall/(precision + recall)\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(f))\n",
    "\n",
    "print('\\nCONFUSION MATRIX ------------------')\n",
    "print(cm)\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_percentages = [\"{0:.2%}\".format(value)\n",
    "                     for value in cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v3}\" for v1, v3 in zip(group_names, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "source": [
    "# Display all model's confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in modelList:\n",
    "    preds = model[0].predict(test_data)\n",
    "\n",
    "    acc = accuracy_score(test_labels, np.round(preds))*100\n",
    "    cm = confusion_matrix(test_labels, np.round(preds))\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    precision = tp/(tp+fp)*100\n",
    "    recall = tp/(tp+fn)*100\n",
    "    f = 2 * precision * recall/(precision + recall)\n",
    "\n",
    "    group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "    group_percentages = [\"{0:.2%}\".format(value)\n",
    "                        for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v3}\" for v1, v3 in zip(group_names, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "    t = model[1].split('_')\n",
    "    title = \"epochs: {} - batch: {} - acc: {}\".format(t[0], t[2].split('b')[1], t[3].split('a')[1])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  }
 ]
}